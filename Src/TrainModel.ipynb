{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Constants as C\n",
    "from MakeModels import *\n",
    "encoder = makeEncoder(c.BatchSz)\n",
    "decoder = makeDecoder()\n",
    "autoencoder = makeAutoencoder(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG,display\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "display(SVG(model_to_dot(autoencoder,show_shapes=True).create(prog='dot', format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "trainPath = '/home/ubuntu/SoftRobotRepresentation/Data/Training'\n",
    "valPath = '/home/ubuntu/SoftRobotRepresentation/Data/Validation'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        trainPath,\n",
    "        target_size=(c.imDim, c.imDim), shuffle=True,\n",
    "        batch_size=c.BatchSz)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        valPath,\n",
    "        target_size=(c.imDim, c.imDim),\n",
    "        batch_size=c.BatchSz)\n",
    "\n",
    "X_batch,y_batch = train_generator.next()\n",
    "# X_batch = X_batch.transpose(0,2,3,1)\n",
    "print X_batch.shape\n",
    "plt.figure()\n",
    "plt.imshow(X_batch[0,:])\n",
    "plt.figure()\n",
    "plt.imshow(X_batch[3,:])\n",
    "\n",
    "# model.fit_generator(\n",
    "#         train_generator,\n",
    "#         samples_per_epoch=2000,\n",
    "#         nb_epoch=50,\n",
    "#         validation_data=validation_generator,\n",
    "#         nb_val_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's test some learning rates\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import tqdm\n",
    "from IPython.core.debugger import Pdb\n",
    "\n",
    "\n",
    "numEpochs = 50\n",
    "numBatchesPerEpoch = 1000\n",
    "nValBatches = 100\n",
    "\n",
    "trainPath = \"/home/ubuntu/SoftRobotRepresentation/Data/Training/0/\"\n",
    "valPath = \"/home/ubuntu/SoftRobotRepresentation/Data/Validation/0/\"\n",
    "\n",
    "def trainGenerator():\n",
    "    files = os.listdir(trainPath)\n",
    "    files = files[:numBatchesPerEpoch*c.BatchSz]\n",
    "    while True:\n",
    "        res = np.zeros(shape=(c.BatchSz,c.imDim,c.imDim,3))\n",
    "        for i in range(numBatchesPerEpoch):\n",
    "            for j in range(c.BatchSz):\n",
    "                res[j,:] = plt.imread(trainPath+files[i*c.BatchSz+j]).astype('float32')/255.0\n",
    "            yield (res,res)\n",
    "        \n",
    "def valGenerator():  \n",
    "    files = os.listdir(valPath)\n",
    "    files = files[:nValBatches*c.BatchSz]\n",
    "    res = np.zeros(shape=(c.BatchSz,c.imDim,c.imDim,3))\n",
    "    while True:\n",
    "        for i in range(nValBatches):\n",
    "            for j in range(c.BatchSz):\n",
    "                res[j,:] = plt.imread(valPath+files[i*c.BatchSz+j]).astype('float32')/255.0\n",
    "            yield (res,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's test some learning rates\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "lr = 0.1\n",
    "print \"Learning rate=\" + str(lr)\n",
    "print \"Compiling model\"\n",
    "autoencoder.compile(optimizer=Adam(lr=lr),loss='mse')\n",
    "print \"Done compiling model\"\n",
    "history = autoencoder.fit_generator(generator=trainGenerator(),\n",
    "                                    samples_per_epoch=numBatchesPerEpoch*c.BatchSz,\n",
    "                                    nb_epoch=numEpochs,\n",
    "                                    validation_data=valGenerator(),\n",
    "                                    nb_val_samples=nValBatches*c.BatchSz,\n",
    "                                    callbacks=[TensorBoard(log_dir='/home/ubuntu/SoftRobotRepresentation/Data/Logs/1'),\n",
    "                                               ModelCheckpoint('/home/ubuntu/SoftRobotRepresentation/Model.h5'),\n",
    "                                               ReduceLROnPlateau(factor=0.2,patience=2)]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder.load_weights('/home/ubuntu/SoftRobotRepresentation/ModelPrettyGoodBottleneck25.h5', by_name=True)\n",
    "im_in = trainGenerator().next()\n",
    "im_in = im_in[0]\n",
    "im_out = autoencoder.predict_on_batch(im_in)\n",
    "print im_out.shape\n",
    "\n",
    "for i in range(c.BatchSz):\n",
    "    plt.figure()\n",
    "    plt.imshow(im_in[i,:])\n",
    "    plt.figure()\n",
    "    plt.imshow(im_out[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = encoder.predict_on_batch(im_in)\n",
    "decoded = decoder.predict_on_batch(encoded)\n",
    "for i in range(c.BatchSz):\n",
    "    plt.figure()\n",
    "    plt.imshow(im_in[i,:])\n",
    "    plt.figure()\n",
    "    plt.imshow(im_out[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import merge, Convolution2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# first, define the vision modules\n",
    "digit_input = Input(shape=(1, 25, 25),name=\"Input1\")\n",
    "x = Convolution2D(64, 3, 3)(digit_input)\n",
    "x = Convolution2D(64, 3, 3)(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out,name=\"Vision\")\n",
    "\n",
    "# then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(1, 27, 27),name=\"Input2\")\n",
    "digit_b = Input(shape=(1, 27, 27),name=\"Input3\")\n",
    "\n",
    "# the vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = merge([out_a, out_b], mode='concat')\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)\n",
    "\n",
    "from IPython.display import SVG,display\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "display(SVG(model_to_dot(classification_model).create(prog='dot', format='svg')))\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's test some learning rates\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import tqdm\n",
    "from IPython.core.debugger import Pdb\n",
    "\n",
    "\n",
    "\n",
    "numEpochs = 100\n",
    "numBatchesPerEpoch = 2\n",
    "nVal = 200\n",
    "\n",
    "trainPath = \"/home/ubuntu/SoftRobotRepresentation/Data/Training/0/\"\n",
    "valPath = \"/home/ubuntu/SoftRobotRepresentation/Data/Validation/0/\"\n",
    "\n",
    "def smallTrainGenerator():\n",
    "    files = os.listdir(trainPath)\n",
    "    files = files[:numBatchesPerEpoch*c.BatchSz]\n",
    "    while True:\n",
    "        res = np.zeros(shape=(c.BatchSz,c.imDim,c.imDim,3))\n",
    "        for i in range(numBatchesPerEpoch):\n",
    "            for j in range(c.BatchSz):\n",
    "                res[j,:] = plt.imread(trainPath+files[i*c.BatchSz+j])\n",
    "            yield (res,res)\n",
    "        \n",
    "def smallValGenerator():  \n",
    "    files = os.listdir(valPath)\n",
    "    files = files[:nVal]\n",
    "    res = np.empty(shape=(0,c.imDim,c.imDim,3))\n",
    "    for i in range(nVal):\n",
    "        im = np.expand_dims(plt.imread(valPath+files[i]),axis=0)\n",
    "        res = np.concatenate((res,im))\n",
    "    yield (res,res)\n",
    "            \n",
    "\n",
    "# def trainModel(model,trainGenerator,validationGenarator):\n",
    "#     loss = []\n",
    "#     validation = []\n",
    "    \n",
    "#     Xtrain = np.empty(shape=(0,c.imDim,c.imDim, 3))\n",
    "#     for i in range(numBatchesPerEpoch):\n",
    "#         train,_ = trainGenerator.next()\n",
    "#         Xtrain = np.concatenate((Xtrain,train.transpose(0,2,3,1)))\n",
    "        \n",
    "#     Xval = np.empty(shape=(0,c.imDim,c.imDim,3))\n",
    "#     for i in range(int(round(nVal/c.BatchSz)):\n",
    "#         val,_ = validationGenarator.next()\n",
    "#         Xval = np.concatenate((Xval,val.transpose(0,2,3,1)))\n",
    "        \n",
    "#     for i in range(numEpochs):\n",
    "#         print \"Epoch %d of %d\" (i+1,numEpochs)\n",
    "#         for j in tqdm(range(numBatchesPerEpoch)):\n",
    "#             Xbatch = Xtrain[j*c.BatchSz:(j+1):c.BatchSz,:]\n",
    "#             loss.append(model.train_on_batch(Xbatch,Xbatch))\n",
    "#         Xbatch, _ = validation_generator.flow()\n",
    "#         validation.append(model.test_on_batch(Xval,Xval))\n",
    "#         print \"Epoch %d, loss = %f, val = %f\" (i+1,loss[-1],validation[-1])\n",
    "        \n",
    "#     return [loss, validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data_gen = smallValGenerator()\n",
    "val_data = val_data_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's test some learning rates\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "histories = []\n",
    "lrs = np.sort(10**random.uniform(-1,2,size=10))\n",
    "for lr in lrs:\n",
    "    print \"Learning rate=\" + str(lr)\n",
    "    print \"Compiling model\"\n",
    "    autoencoder.compile(optimizer=Adam(lr=lr),loss='mse')\n",
    "    print \"Done compiling model\"\n",
    "    \n",
    "    \n",
    "#     [loss,val] = trainModel(numEpochs=numEpochs,\n",
    "#                             numBatchesPerEpoch=numBatchesPerEpoch,\n",
    "#                             nVal=nVal,\n",
    "#                             model=autoencoder,\n",
    "#                             trainGenerator=train_generator,\n",
    "#                             validationGenarator=validation_generator)\n",
    "    history = autoencoder.fit_generator(generator=smallTrainGenerator(),\n",
    "                                        samples_per_epoch=numBatchesPerEpoch*c.BatchSz,\n",
    "                                        nb_epoch=numEpochs,\n",
    "                                        validation_data=val_data,\n",
    "                                        callbacks=[TensorBoard(log_dir='/home/ubuntu/SoftRobotRepresentation/Data/Logs')]\n",
    "                                       )\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load 'MakeModels.py'\n",
    "from keras.layers import merge, Deconvolution2D, UpSampling2D, Convolution2D, MaxPooling2D, Input, Dense, Flatten, Merge, BatchNormalization, LeakyReLU, LSTM\n",
    "from keras.models import Model\n",
    "import os\n",
    "\n",
    "nBottleneck = 25\n",
    "\n",
    "imageInput = Input(shape=(c.imDim, c.imDim, 3))\n",
    "\n",
    "nWindow = 1\n",
    "lstmTimeSize = 32\n",
    "positionInput = Input(shape=(2*nWindow,))\n",
    "nHiddenLSTM = 64\n",
    "\n",
    "def makeEncoder(c.BatchSz):\n",
    "    gc.BatchSz = c.BatchSz\n",
    "    # first, define the encoder\n",
    "\n",
    "    # c.imDim x c.imDim input\n",
    "    x = Convolution2D(32, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(imageInput)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 128 x 128 input\n",
    "    x = Convolution2D(32, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 64 x 64 input\n",
    "    x = Convolution2D(32, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 32 x 32 input\n",
    "    x = Convolution2D(64, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 16 x 16 input\n",
    "    x = Convolution2D(128, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 8 x 8 input\n",
    "    x = Convolution2D(128, 4, 4, subsample=(2, 2), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 4 x 4 input\n",
    "    encodedFeatures = Convolution2D(nBottleneck, 4, 4, subsample=(1, 1), border_mode='valid', dim_ordering='tf')(x)\n",
    "\n",
    "    encoder_model = Model(imageInput, encodedFeatures, name='Encoder')\n",
    "    return encoder_model\n",
    "\n",
    "def makeDecoder():\n",
    "    # decoder_model \n",
    "    encoded_input = Input(shape=(1,1,nBottleneck))\n",
    "\n",
    "    # 1,1,2000 input\n",
    "    x = UpSampling2D(size=(4,4),dim_ordering='tf')(encoded_input)\n",
    "    x = Convolution2D(128, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 4x4x512 input\n",
    "    x = Convolution2D(128, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 8x8xc.imDim input\n",
    "    x = Convolution2D(64, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 16x16xc.imDim input\n",
    "    x = Convolution2D(64, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 32x32x128 input\n",
    "    x = Convolution2D(64, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 64x64x64 input\n",
    "    x = Convolution2D(32, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 128x128x64 input\n",
    "    x = Convolution2D(3, 4, 4, subsample=(1, 1), border_mode='same', dim_ordering='tf')(x)\n",
    "    x = UpSampling2D(size=(2,2),dim_ordering='tf')(x)\n",
    "\n",
    "    generator_model = Model(encoded_input,x,name=\"Decoder\")\n",
    "    return generator_model\n",
    "\n",
    "def makeAutoencoder(encoder_model, generator_model):\n",
    "    x = encoder_model(imageInput)\n",
    "    x = generator_model(x)\n",
    "    autoencoder = Model(imageInput, x)\n",
    "    return autoencoder\n",
    "\n",
    "def makePlainLSTM():\n",
    "    x = K.expand_dims(position_input,axis=0)\n",
    "    x = LSTM(nHiddenLSTM)(positionInput)\n",
    "    x = Dense(round(nHiddenLSTM/2))(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1)(x)\n",
    "    plainLSTM = Model(positionInput,x)\n",
    "    return plainLSTM\n",
    "\n",
    "def makeImageLSTM(encoder):\n",
    "    y = encoder(imageInput)\n",
    "    x = Merge([positionInput,y],mode='concat')\n",
    "    x = K.expand_dims(x,axis=0)\n",
    "    x = LSTM(nHiddenLSTM)(x)\n",
    "    x = Dense(round(nHiddenLSTM/2))(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1)(x)\n",
    "    imageLSTM = Model(inputs=[positionInput,imageInput],x)\n",
    "    return imageLSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
